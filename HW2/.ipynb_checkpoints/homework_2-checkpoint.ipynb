{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Classification\n",
    "\n",
    "In this exercise you will use scikit-learn, a popular machine learning package in python to train and tune a classifier. A particularly useful feature is that all classifiers (and linear models) are called using the same API, so it is easy to test between different models (see the sklearn-intro notebook for examples). So in this exercise we will a classification technique (logistic regression) that is representative of methods and challenges you will encounter when using any classification method.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "We will be using a banking marketing dataset. \n",
    "The dataset is associated with direct marketing campaigns of a banking institution. Your job is to find out the best strategies to improve for the next marketing campaign. How can the bank have a greater effectiveness for future marketing campaigns? In order to answer this, we have to analyze the last marketing campaign the bank performed and identify the patterns that will help us find conclusions in order to develop future strategies.\n",
    "\n",
    "You have to predict whether a customer subscribes for term deposit or not using the following attributes: \n",
    "\n",
    "1 - age (numeric)<br>\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')<br>\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)<br>\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')<br>\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')<br>\n",
    "6 - balance: balance amount (numeric)<br>\n",
    "7 - housing: has housing loan? (categorical: 'no','yes','unknown')<br>\n",
    "8 - loan: has personal loan? (categorical: 'no','yes','unknown')<br>\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')<br>\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br>\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br>\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br>\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br>\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)<br>\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br>\n",
    "\n",
    "features_ex2.xlsx contains the features. It has 4521 records. First 3165 observations are used for training dataset, next 678 observations are used for cross validation dataset and final 678 observations are used for test dataset.\n",
    "\n",
    "label_ex2.xlsx contains the label: \"yes\" or \"no\". First 3165 observations are used for training dataset, next 678 observations are used for cross validation dataset. Labels for test dataset are not provided to you because in a real world scenario you will not know the true values for your test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  campaign  pdays  previous poutcome  \n",
       "0  cellular   19   oct         1     -1         0  unknown  \n",
       "1  cellular   11   may         1    339         4  failure  \n",
       "2  cellular   16   apr         1    330         1  failure  \n",
       "3   unknown    3   jun         4     -1         0  unknown  \n",
       "4   unknown    5   may         1     -1         0  unknown  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_excel(\"features_ex2.xlsx\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y\n",
       "0  no\n",
       "1  no\n",
       "2  no\n",
       "3  no\n",
       "4  no"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_excel(\"label_ex2.xlsx\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting strings to binary variables\n",
    "mapping = {'yes': 1, 'no': 0}\n",
    "y.y = [mapping[i] for i in y.y]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['job','marital','education','default','housing','loan','contact','month','poutcome']\n",
    "categorical = pd.get_dummies(X[categories])\n",
    "continuous = X.drop(columns=categories)\n",
    "X = pd.concat([continuous,categorical],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train, cv and test set (70:15:15 ratio)\n",
    "X_train = X.iloc[0:3165,:].copy()\n",
    "y_train = y.iloc[0:3165,:].copy()\n",
    "X_cv = X.iloc[3165:3843,:].copy()\n",
    "y_cv = y.iloc[3165:3843,:].copy()\n",
    "X_test = X.iloc[3843:4521,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (3165, 50)\n",
      "y_train (3165, 1)\n",
      "X_cv (678, 50)\n",
      "y_cv (678, 1)\n",
      "X_test (678, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train \"+ str(X_train.shape))\n",
    "print(\"y_train \"+ str(y_train.shape))\n",
    "print(\"X_cv \"+ str(X_cv.shape))\n",
    "print(\"y_cv \"+ str(y_cv.shape))\n",
    "print(\"X_test \"+ str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "As discussed in previous exercise, standardization is important when a number of features with different scales are involed. \n",
    "\n",
    "Q. Use StandardScaler from sklearn.preprocessing to standardize the continuous features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "continuous_variables = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Use the above list to replace the continuous columns in X_train to scaled columns. Use fit_transform method.\n",
    "### WRITE CODE HERE\n",
    "X_train[continuous_variables] = scaler.fit_transform(X_train[continuous_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarily use the above list to replace the continuous columns in X_cv and X_test to scaled columns. \n",
    "# Use transform method.\n",
    "### WRITE CODE HERE\n",
    "\n",
    "X_cv[continuous_variables] = scaler.transform(X_cv[continuous_variables])\n",
    "X_test[continuous_variables] = scaler.transform(X_test[continuous_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "As previously mentioned, the scikit-learn classification API makes it easy to train a classifier. \n",
    "\n",
    "\n",
    "Q. Use LogisticRegression from sklearn.linear_model to make a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, initialize the classifier with default parameters\n",
    "\n",
    "# then fit the classifier on training data and labels\n",
    "\n",
    "### WRITE CODE HERE\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output for cross validation dataset\n",
    "\n",
    "### WRITE CODE HERE\n",
    "\n",
    "y_cv_pred = logisticRegr.predict(X_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement precision(), recall(), accuracy() in exercise_2.py, and use them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_utils import accuracy, precision, recall\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy || sklearn_check\n",
      "0.891    || 0.891     \n",
      "Precision|| sklearn_check\n",
      "0.45     || 0.45      \n",
      "Recall   || sklearn_check\n",
      "0.125    || 0.125     \n"
     ]
    }
   ],
   "source": [
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "\n",
    "### WRITE CODE HERE\n",
    "\n",
    "acc = accuracy(y_cv.values.ravel(), y_cv_pred)\n",
    "prec = precision(y_cv.values.ravel(), y_cv_pred)\n",
    "rec = recall(y_cv.values.ravel(), y_cv_pred)\n",
    "\n",
    "# Checking with sklearn \n",
    "acc_score = logisticRegr.score(X_cv, y_cv)\n",
    "prec_score = precision_score(y_cv, y_cv_pred)\n",
    "rec_score = recall_score(y_cv, y_cv_pred)\n",
    "\n",
    "print(f'{\"Accuracy\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(acc,3):<9}|| {round(acc_score,3):<10}')\n",
    "\n",
    "print(f'{\"Precision\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(prec,3):<9}|| {round(prec_score,3):<10}')    \n",
    "\n",
    "print(f'{\"Recall\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(rec,3):<9}|| {round(rec_score,3):<10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Accuracy<br>\n",
    "Ans - 89.1%\n",
    "\n",
    "Q. Precision<br>\n",
    "Ans - 45%\n",
    "\n",
    "Q. Recall<br>\n",
    "Ans - 12.5%\n",
    "\n",
    "Q. Which metric (accuracy, precision, recall) is more appropriate and in what cases? Will there be scenarios where it is better to use precision than accuracy? Explain. <br>\n",
    "\n",
    "Ans - Accuracy is a basic metric representing the fraction of correctly predicted values. In most cases it's more than enough for result checking. However, sometimes we can have an 'imbalanced classification problem' where our classes are not equally represented. As an example we can take terrorist detection in airports and disease diagnosing. In case of terrorist detection we can obtain very high accuracy simply labeling all the passengers as not terrorists but logically it would not be a good model. That's where we use precision or recall as metrics. \n",
    "\n",
    "These metrics are in trade-off, higher recall leads to lower precision and vice-versa. In some cases (when we have a high cost of false negative) such as disease detection we would like to maximize recall to detect all patients who actially have the disease. In other hand if we have a high cost of false positive (for example spam detection) we should pick precision as our main metric. \n",
    "\n",
    "Q. Which metric is suitable in this case? <br>\n",
    "Ans - In this case we have 90 % of 'no' and 10% of 'yes' variables so that said we are dealing with highly skewed data. Since for marketing campaign budgeting it's important to justify the investments and hit the target amount of subsciptions we would like to choose precision in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "\n",
    "Q. Use roc_Curve from sklearn.metrics and use matplotlib.pyplot to plot the ROC curve. Use cv set to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "### WRITE CODE HERE\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_cv.values.ravel(), logisticRegr.predict_proba(X_cv)[:,1])\n",
    "auc = roc_auc_score(y_cv.values.ravel(), logisticRegr.predict_proba(X_cv)[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the ROC curve by giving appropriate names for title and axes. \n",
    "\n",
    "### WRITE CODE HERE\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve, AOC = {round(auc,2)}')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. What is the AOC obtained?<br>\n",
    "Ans - 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "\"Model tuning\" refers to model adjustments to better fit the data. This is separate from \"fitting\" or \"training\" the model. The fitting/training procedure is governed by the amount and quality of your training data, as the fitting algorithm is unique to each classifier (e.g. logistic regression or random forest). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.1 and penalty set to 'l1'. Make predictions on cross validation set and compute accuracy, precision and recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy || sklearn_check\n",
      "0.898    || 0.898     \n",
      "Precision|| sklearn_check\n",
      "0.6      || 0.6       \n",
      "Recall   || sklearn_check\n",
      "0.125    || 0.125     \n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "\n",
    "logisticRegr2 = LogisticRegression(penalty = 'l1', C = 0.1)\n",
    "logisticRegr2.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_cv_pred2 = logisticRegr2.predict(X_cv)\n",
    "\n",
    "acc_mod2 = accuracy(y_cv.values.ravel(), y_cv_pred2)\n",
    "prec_mod2 = precision(y_cv.values.ravel(), y_cv_pred2)\n",
    "rec_mod2 = recall(y_cv.values.ravel(), y_cv_pred2)\n",
    "\n",
    "acc_score_mod2 = logisticRegr2.score(X_cv, y_cv)\n",
    "prec_score_mod2 = precision_score(y_cv, y_cv_pred2)\n",
    "rec_score_mod2 = recall_score(y_cv, y_cv_pred2)\n",
    "\n",
    "print(f'{\"Accuracy\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(acc_mod2,3):<9}|| {round(acc_score_mod2,3):<10}')\n",
    "\n",
    "print(f'{\"Precision\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(prec_mod2,3):<9}|| {round(prec_score_mod2,3):<10}')    \n",
    "\n",
    "print(f'{\"Recall\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(rec_mod2,3):<9}|| {round(rec_score_mod2,3):<10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.5 and penalty set to 'l1'. Make predictions on cross validation set and compute accuracy, precision and recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy || sklearn_check\n",
      "0.894    || 0.894     \n",
      "Precision|| sklearn_check\n",
      "0.5      || 0.5       \n",
      "Recall   || sklearn_check\n",
      "0.139    || 0.139     \n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "\n",
    "logisticRegr3 = LogisticRegression(penalty = 'l1', C = 0.5)\n",
    "logisticRegr3.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_cv_pred3 = logisticRegr3.predict(X_cv)\n",
    "\n",
    "acc_mod3 = accuracy(y_cv.values.ravel(), y_cv_pred3)\n",
    "prec_mod3 = precision(y_cv.values.ravel(), y_cv_pred3)\n",
    "rec_mod3 = recall(y_cv.values.ravel(), y_cv_pred3)\n",
    "\n",
    "acc_score_mod3 = logisticRegr3.score(X_cv, y_cv)\n",
    "prec_score_mod3 = precision_score(y_cv, y_cv_pred3)\n",
    "rec_score_mod3 = recall_score(y_cv, y_cv_pred3)\n",
    "\n",
    "print(f'{\"Accuracy\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(acc_mod3,3):<9}|| {round(acc_score_mod3,3):<10}')\n",
    "\n",
    "print(f'{\"Precision\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(prec_mod3,3):<9}|| {round(prec_score_mod3,3):<10}')    \n",
    "\n",
    "print(f'{\"Recall\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(rec_mod3,3):<9}|| {round(rec_score_mod3,3):<10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.1 and penalty set to 'l2'. Make predictions on cross validation set and compute accuracy, precision and recall. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy || sklearn_check\n",
      "0.898    || 0.898     \n",
      "Precision|| sklearn_check\n",
      "0.6      || 0.6       \n",
      "Recall   || sklearn_check\n",
      "0.125    || 0.125     \n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "\n",
    "logisticRegr4 = LogisticRegression(penalty = 'l2', C = 0.1)\n",
    "logisticRegr4.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_cv_pred4 = logisticRegr4.predict(X_cv)\n",
    "\n",
    "acc_mod4 = accuracy(y_cv.values.ravel(), y_cv_pred4)\n",
    "prec_mod4 = precision(y_cv.values.ravel(), y_cv_pred4)\n",
    "rec_mod4 = recall(y_cv.values.ravel(), y_cv_pred4)\n",
    "\n",
    "acc_score_mod4 = logisticRegr4.score(X_cv, y_cv)\n",
    "prec_score_mod4 = precision_score(y_cv, y_cv_pred4)\n",
    "rec_score_mod4 = recall_score(y_cv, y_cv_pred4)\n",
    "\n",
    "print(f'{\"Accuracy\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(acc_mod4,3):<9}|| {round(acc_score_mod4,3):<10}')\n",
    "\n",
    "print(f'{\"Precision\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(prec_mod4,3):<9}|| {round(prec_score_mod4,3):<10}')    \n",
    "\n",
    "print(f'{\"Recall\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(rec_mod4,3):<9}|| {round(rec_score_mod4,3):<10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model with hyperparameter 'C' set to 0.5 and penalty set to 'l2'. Make predictions on cross validation set and compute accuracy, precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy || sklearn_check\n",
      "0.892    || 0.892     \n",
      "Precision|| sklearn_check\n",
      "0.474    || 0.474     \n",
      "Recall   || sklearn_check\n",
      "0.125    || 0.125     \n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE HERE\n",
    "\n",
    "logisticRegr5 = LogisticRegression(penalty = 'l2', C = 0.5)\n",
    "logisticRegr5.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_cv_pred5 = logisticRegr5.predict(X_cv)\n",
    "\n",
    "acc_mod5 = accuracy(y_cv.values.ravel(), y_cv_pred5)\n",
    "prec_mod5 = precision(y_cv.values.ravel(), y_cv_pred5)\n",
    "rec_mod5 = recall(y_cv.values.ravel(), y_cv_pred5)\n",
    "\n",
    "acc_score_mod5 = logisticRegr5.score(X_cv, y_cv)\n",
    "prec_score_mod5 = precision_score(y_cv, y_cv_pred5)\n",
    "rec_score_mod5 = recall_score(y_cv, y_cv_pred5)\n",
    "\n",
    "print(f'{\"Accuracy\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(acc_mod5,3):<9}|| {round(acc_score_mod5,3):<10}')\n",
    "\n",
    "print(f'{\"Precision\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(prec_mod5,3):<9}|| {round(prec_score_mod5,3):<10}')    \n",
    "\n",
    "print(f'{\"Recall\":<9}|| {\"sklearn_check\":<10}')\n",
    "print(f'{round(rec_mod5,3):<9}|| {round(rec_score_mod5,3):<10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Which of the above models is better? <br>\n",
    "Ans- Two models with 'l1' and 'l2' having C = 0.1 are equally good, but since 'l1' model is simpler - and thus, computationally cheaper (because of lasso regularization) we would prefer the model with 'l1' and C = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set\n",
    "\n",
    "You have worked on training and cv dataset so far, but testing data does not include the labels. Choose the best hyperparameter values as seen in previous section and build a model. Use this model to make predictions on test set. You will submit a csv file containing your predictions names as predictions.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### Construct your final logistic regression using the best hyperparameters obtained above(C and penalty) ###\n",
    "final_model = logisticRegr2\n",
    "final_model.fit(X_train, y_train.values.ravel())\n",
    "predicted = final_model.predict(X_test)\n",
    "\n",
    "# Converting binary variables back to strings \n",
    "mapping = {1: 'yes', 0:'no'}\n",
    "predicted = [mapping[i] for i in predicted]\n",
    "\n",
    "### save into csv with column heading as \"y\"\n",
    "pred_df = pd.DataFrame(predicted, columns = ['y'])\n",
    "pred_df.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
